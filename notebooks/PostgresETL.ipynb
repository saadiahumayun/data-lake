{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc00d27-f2dc-428a-9924-b64dc1a7bf92",
   "metadata": {},
   "source": [
    "# Starting Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccbcb052-e803-4a44-8135-3bbbfe5d2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from pyspark import SparkConf, SparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "829ad0fa-dbeb-4161-bbbf-f881394894f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark as ps\n",
    "import warnings\n",
    "from pyspark.sql import SQLContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e0a0ab-3e61-4883-9156-b70b2cae4d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just created a SparkContext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sc = ps.SparkContext('local')\n",
    "sqlContext = SQLContext(sc)\n",
    "print(\"Just created a SparkContext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4072addd-ebc4-4f58-a86b-f3437c1a6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark session & context\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master(\"local\")\n",
    "         .appName(\"load-postgres\")\n",
    "\n",
    "         # Add postgres jar\n",
    "         .config(\"spark.driver.extraClassPath\", \"/home/jovyan/work/jars/postgresql-42.4.0.jar\")\n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36dfb9f-4031-4acf-98fe-6e0f8ad83030",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d73a8-1dbe-4d64-99a2-a9a12ed7ac38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53caa7dd-aff3-4ff6-bdb8-a0587f0236a2",
   "metadata": {},
   "source": [
    "# Extract\n",
    "\n",
    "* Here we read data from mounted volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656a9a30-58c4-4e55-8e68-f7dc9d596dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_movies_csv = pd.read_csv(\"/home/jovyan/work/data/movies.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54391956-3829-4c90-8269-6039d80f0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_csv = (\n",
    "    pd.read_csv(\"/home/jovyan/work/data/ratings.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10a3b35-c6d6-40f2-8b8d-40d45a33c803",
   "metadata": {},
   "source": [
    "# Transform\n",
    "\n",
    "* Convert Timestamp column to Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5022879-53d3-42d9-bd26-2b37db3debf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert epoch to timestamp and rating to DoubleType\n",
    "from pyspark.sql.functions import from_unixtime, col, to_timestamp\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a383d62-e6ee-4050-a196-0240456239ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_csv_fmt = (\n",
    "    df_ratings_csv\n",
    "    .withColumn('rating', col(\"rating\").cast(DoubleType()))\n",
    "    .withColumn('timestamp', to_timestamp(from_unixtime(col(\"timestamp_epoch\"))))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1fa853-664e-422f-8f17-b5d2235469b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c70de37-6f76-4819-aced-93c3be0d4639",
   "metadata": {},
   "source": [
    "# Load \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706d7a4-4ed7-4417-aa9c-34ed2cb6741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.write.format(\"jdbc\").option(\"url\", \"jdbc:postgresql://host.docker.internal:5432/airflow\").option(\"dbtable\", \"public.movies1\").option(\"user\", \"airflow\").option(\"password\", \"airflow\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f622dfd-6510-4264-b801-646856674083",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sqlalchemy\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972cc879-b18d-4d65-8680-a8dbadd8df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ecbf7-0aab-447a-9cd4-4eba5b8c2c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    host=\"host.docker.internal\",\n",
    "    port=\"5432\",\n",
    "    database=\"airflow\",\n",
    "    user=\"airflow\",\n",
    "    password=\"airflow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79709921-fe42-44af-b6ad-19e162e456b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc9779f-936c-431a-a144-86b3f11513b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example format\n",
    "%sql postgresql://airflow:airflow@host.docker.internal:5432/airflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28462d43-819f-4733-86cb-cb0f12d07937",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbabcb5d-1c6a-452e-b571-e5b7e99b35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_ratings_csv\n",
    " .select([c for c in df_ratings_csv_fmt.columns if c != \"timestamp_epoch\"])\n",
    " .write\n",
    " .format(\"jdbc\")\n",
    " .option(\"url\", \"jdbc:postgresql://host.docker.internal:5432/airflow\")\n",
    " .option(\"dbtable\", \"public.ratings1\")\n",
    " .option(\"user\", \"airflow\")\n",
    " .option(\"password\", \"airflow\")\n",
    " .mode(\"overwrite\")\n",
    " .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1071e98-a301-4236-871a-707dec56f879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973f21e-ee0f-47e7-95b9-1d4acff45bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
